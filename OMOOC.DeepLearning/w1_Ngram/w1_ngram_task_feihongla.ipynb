{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feihongla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import jieba.posseg as pseg\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.640 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lm = defaultdict(Counter) #设定一个语言模型\n",
    "ngram = 2 #下一个词生成所依赖的词数\n",
    "\n",
    "#获取参考文章内容\n",
    "line_no = 0\n",
    "limit = 20000\n",
    "wordlist = []\n",
    "    #逐行读取参考文章\n",
    "for line in open('../AssisantEvaluate/西游记.txt'):\n",
    "    line_no +=1\n",
    "    if line_no > limit:\n",
    "        continue\n",
    "    words = pseg.cut(line.strip())#词性分词\n",
    "    for word, flag in words:\n",
    "        wordlist.append(word.encode(\"utf-8\")) #生成词语列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_count(wordlist):\n",
    "    for i in range (ngram, len(wordlist)):\n",
    "        context = tuple(wordlist[i-ngram:i])\n",
    "        word = wordlist[i]\n",
    "        lm[context][word] +=1 #计算context下word的词频\n",
    "    \n",
    "    for context, word_cnt in lm.items():\n",
    "        s = float(sum(word_cnt.values()))\n",
    "        for word, cnt in word_cnt.items():\n",
    "            lm[context][word] = cnt / s\n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(context):\n",
    "    r = random.random()\n",
    "    s = 0.0\n",
    "    for word, prob in lm[context].items():\n",
    "        s += prob\n",
    "        if s > r:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "逼将去，你返说我和你——若是真王登宝座，自你回那里去？”那牛王正与玉面公主，唤做定心真言。来回念了几遍，把果子敲下十个，还请他登坛祈祷，果有一座濯垢泉洗澡之事，这般寒冷？”唐僧道：“四位长老，死了也！”土地道：“只怕是拿你救唐僧！”叫：“师兄，这里全没眼色，认不得人。我那两件宝贝，万夫不当之勇。我们拿他往下一掼，掼杀他。他伤的是个撞头的和尚，甚是不过意，连忙遮掩，收拾出城罢。”菩萨即穿袈裟，叩头上告道：“哥呀，那国王丢了磁杯，望他神气色，冷落粉墙东。行者把锣往地下一掼。有人吃他一块肉，延寿长生。我只说是走出皇宫，不成功果，炼成了了自逍遥\n"
     ]
    }
   ],
   "source": [
    "sentence = [] #空的句子列表\n",
    "\n",
    "r_int = random.randint(0, len(wordlist)-ngram+1)\n",
    "for i in range (r_int, r_int+ngram):\n",
    "    sentence.append(wordlist[i]) #采样首词\n",
    "\n",
    "gram_count(wordlist)\n",
    "#根据首词生成其余词语，组成句子\n",
    "for i in range(ngram, 200):\n",
    "    context = ()\n",
    "    for j in range (ngram):\n",
    "        context += (sentence[i-(ngram-j)],) #选取已有句子倒数ngram个词语生成context，来generate大概率的词语word\n",
    "    sentence.append(generate(context)) #将generate采样出来的word添加到已有句子列表上，继续循环直至要求的词语数为止\n",
    "    \n",
    "print(\"\".join(sentence)) #将添加完的词语生成句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
