{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import log\n",
    "import jieba\n",
    "\n",
    "def readfile(file_path):\n",
    "    with open(file_path.encode('utf-8')) as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5288782233791589, 0.47112177662084115]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先验概率\n",
    "pos_count = float(len(readfile('pos_train.txt')))\n",
    "neg_count = float(len(readfile('neg_train.txt')))\n",
    "sums = pos_count + neg_count\n",
    "prior = [(neg_count / sums), (pos_count / sums)]\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.312 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#分词计数\n",
    "def model(train_file):\n",
    "    lm = Counter()\n",
    "    for line in readfile(train_file):\n",
    "        for word in jieba.cut(line):\n",
    "            lm[word] += 1\n",
    "    return lm\n",
    "\n",
    "#获取所有词\n",
    "def list():\n",
    "    lm_pos = model('pos_train.txt')\n",
    "    lm_neg = model('neg_train.txt')\n",
    "    s = [lm_neg, lm_pos]\n",
    "    wordlist = set()\n",
    "    for i in(0,1):\n",
    "        for word in s[i].items():\n",
    "            wordlist.add(word)\n",
    "    return wordlist\n",
    "wordlist = list()\n",
    "\n",
    "#条件概率\n",
    "def get(train_file):\n",
    "    v_count = len(wordlist)\n",
    "    goal = model(train_file)\n",
    "    sum_ = float(sum(goal.values()))\n",
    "    get = Counter()\n",
    "    for word, cnt in goal.items():\n",
    "        get[word] = (cnt + 1) / (sum_ + v_count + 1)\n",
    "    get = defaultdict(lambda: 1 / (sum_ + v_count + 1), get)\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练词料条件概率\n",
    "pos_train_lm = get('pos_train.txt')\n",
    "neg_train_lm = get('neg_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#算出测试语料后验概率\n",
    "def classify(content, pos_train_lm, neg_train_lm, i):\n",
    "    words = jieba.cut(content)\n",
    "    result = log(prior[i])\n",
    "    for word in words:\n",
    "        #if word in wordlist:\n",
    "        result += log(pos_train_lm[word] / neg_train_lm[word])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算情感分类\n",
    "s_test = ['neg_test.txt', 'pos_test.txt']\n",
    "r = [[0,0],[0,0]]\n",
    "for i in (0,1):\n",
    "    for line in open(s_test[i]):\n",
    "        if classify(line,pos_train_lm, neg_train_lm,i)<0:\n",
    "            r[i][0] +=1\n",
    "        else:\n",
    "            r[i][1] +=1\n",
    "total = r[0][0]+r[0][1]+r[1][0]+r[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4990, 583], [1267, 3698]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n=10538     predicted:neg  predicted:pos \n",
      "  actual:neg        4990           1267      \n",
      "  actual:pos         583           3698      \n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = ('\\n'.join(['{:^15}' * 3] * 3)).format(\n",
    "    'n='+str(total), 'predicted:neg', 'predicted:pos',\n",
    "    'actual:neg', r[0][0], r[1][0],\n",
    "    'actual:pos', r[0][1], r[1][1])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975067923925204"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4990.0/(4990+1267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863816865218407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3698.0/(583+3698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
