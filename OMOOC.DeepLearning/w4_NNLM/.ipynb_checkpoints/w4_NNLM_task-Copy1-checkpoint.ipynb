{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业4\n",
    "\n",
    "请根据这个基本的框架程序进行扩展，使用你的语料库进行训练。并完成 3 个名词各自最相近的 Top 10 个词的检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 决定了 embedding 的维度 （隐层节点数）\n",
    "word_embedding_dim = 50\n",
    "# 决定了词表数量, 预留一个未登录词\n",
    "vocab_size = 5000 + 1\n",
    "UNK_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "input_data = tf.placeholder(tf.int32, shape=[None, 2], name='input_data')\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_data:0' shape=(?, 2) dtype=int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, 2, 50) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词向量相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_embeds = tf.reduce_sum(input_embeds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(?, 50) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 映射到 N 个词的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_output 是一个 vocab_size 维的数据，对比 labels 计算 cost\n",
    "# 假设输入一组（也就是 两个词），输出因为词向量相加过了，所以就是一个词的词向量：one-hot？\n",
    "raw_output = tf.layers.dense(context_embeds, vocab_size)\n",
    "# 如果输入一组，输出的 softmax 是预测的 one-hot 的概率分布？最可能的那个输出词概率最大？\n",
    "output = tf.nn.softmax(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(?, 5001) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 5001) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 样本的 labels 也需要用 placeholder 放置\n",
    "labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "# 因为我们每个样本的 label 只有一个，使用稠密的 softmax 算 cost 及求导太浪费了。这里使用 sparse 版本即可。\n",
    "# 如果你的 label 是完整的 N 个词上的概率分布，这时候可以使用 tf.nn.softmax_cross_entropy_with_logits\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=raw_output, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取语料，生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 2.013 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "line_no = 0\n",
    "words = []\n",
    "with open('../AssisantEvaluate/xiyouji.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line_no += 1\n",
    "        if line_no > 1000:\n",
    "            break\n",
    "        word = pseg.cut(line.strip().decode('utf-8')) # 去掉末尾的 '\\n'\n",
    "        for w,f in word:\n",
    "            if f == 'x':\n",
    "                continue\n",
    "            words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12951"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 统计词频\n",
    "word_cnt = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4271"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 高频截断\n",
    "vocab = [i[0] for i in word_cnt.most_common(vocab_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab2 = [i for i in word_cnt.most_common(vocab_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 插入未登录词\n",
    "vocab.insert(UNK_IDX, 'UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4272"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 映射 id\n",
    "word_ids = [vocab.index(word) if (word in vocab) else 0 for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12951"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "inputs_train = np.asarray([[word_ids[i-1], word_ids[i+1]] for i in range(1, len(word_ids) - 1)])\n",
    "labels_train = np.asarray(word_ids[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12949, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12949,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Cost 矩阵：\n",
      "[ 8.46947861  8.70240974  8.51500702 ...,  8.52219391  8.53361893\n",
      "  8.62042809]\n",
      "Cost 矩阵 shape：\n",
      "(12949,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[ 0.00016214  0.00499354  0.00403204 ...,  0.00017288  0.00022578\n",
      "   0.0001712 ]\n",
      " [ 0.00018793  0.00441139  0.00302746 ...,  0.0001844   0.0002285\n",
      "   0.00017684]\n",
      " [ 0.0001844   0.00637549  0.00454337 ...,  0.00018741  0.00020938\n",
      "   0.00016976]\n",
      " ..., \n",
      " [ 0.0001875   0.00328416  0.00245423 ...,  0.000186    0.00021589\n",
      "   0.00017929]\n",
      " [ 0.00019016  0.00389575  0.00285878 ...,  0.00019536  0.00018857\n",
      "   0.0001966 ]\n",
      " [ 0.00020657  0.00282421  0.00207521 ...,  0.00017948  0.00023854\n",
      "   0.00016293]]\n",
      "Output 矩阵 shape：\n",
      "(12949, 5001)\n",
      "(5001,)\n",
      "---\n",
      "Probability: 0.000351\n",
      "------\n",
      "Iteration 2\n",
      "Cost 矩阵：\n",
      "[ 8.70068836  8.87510777  8.79085541 ...,  8.6526823   8.56001854\n",
      "  8.56023788]\n",
      "Cost 矩阵 shape：\n",
      "(12949,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[ 0.00012594  0.00333472  0.01460561 ...,  0.00013431  0.0001739\n",
      "   0.00013341]\n",
      " [ 0.00015351  0.00301888  0.01059209 ...,  0.00015065  0.00018517\n",
      "   0.0001449 ]\n",
      " [ 0.00013704  0.0040509   0.0168997  ...,  0.00013929  0.00015424\n",
      "   0.00012659]\n",
      " ..., \n",
      " [ 0.00016102  0.00241527  0.00803446 ...,  0.00015975  0.00018405\n",
      "   0.00015441]\n",
      " [ 0.00016165  0.00284875  0.00966691 ...,  0.00016609  0.00015911\n",
      "   0.00016761]\n",
      " [ 0.00017958  0.0021348   0.00654311 ...,  0.00015606  0.00020591\n",
      "   0.00014204]]\n",
      "Output 矩阵 shape：\n",
      "(12949, 5001)\n",
      "(5001,)\n",
      "---\n",
      "Probability: 0.000659\n",
      "------\n",
      "Iteration 4\n",
      "Cost 矩阵：\n",
      "[ 8.81204987  8.96451378  8.92056274 ...,  8.72797775  8.52893257\n",
      "  8.45914841]\n",
      "Cost 矩阵 shape：\n",
      "(12949,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[ 0.00011026  0.0062352   0.00414606 ...,  0.0001176   0.00015123\n",
      "   0.00011712]\n",
      " [ 0.00013652  0.005331    0.0032259  ...,  0.00013399  0.00016362\n",
      "   0.00012919]\n",
      " [ 0.00011781  0.00772807  0.00445018 ...,  0.00011977  0.00013166\n",
      "   0.00010914]\n",
      " ..., \n",
      " [ 0.00014623  0.00418415  0.00267246 ...,  0.0001451   0.00016615\n",
      "   0.00014056]\n",
      " [ 0.00014633  0.00500627  0.00321295 ...,  0.00015037  0.00014317\n",
      "   0.0001521 ]\n",
      " [ 0.00016409  0.00367847  0.0022485  ...,  0.00014261  0.00018707\n",
      "   0.00013009]]\n",
      "Output 矩阵 shape：\n",
      "(12949, 5001)\n",
      "(5001,)\n",
      "---\n",
      "Probability: 0.001252\n",
      "------\n",
      "Iteration 6\n",
      "Cost 矩阵：\n",
      "[ 8.88992214  9.02603149  9.00766087 ...,  8.78227806  8.48068523\n",
      "  8.34636688]\n",
      "Cost 矩阵 shape：\n",
      "(12949,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  9.98349060e-05   1.26877346e-03   9.69047379e-03 ...,   1.06496955e-04\n",
      "    1.36127070e-04   1.06289714e-04]\n",
      " [  1.24984595e-04   1.14852295e-03   7.22099934e-03 ...,   1.22686339e-04\n",
      "    1.48967636e-04   1.18536627e-04]\n",
      " [  1.05687337e-04   1.45318767e-03   1.07510881e-02 ...,   1.07455577e-04\n",
      "    1.17392912e-04   9.81460325e-05]\n",
      " ..., \n",
      " [  1.35689814e-04   1.02436356e-03   5.62793016e-03 ...,   1.34658840e-04\n",
      "    1.53397792e-04   1.30704459e-04]\n",
      " [  1.35440743e-04   1.20367378e-03   6.97026541e-03 ...,   1.39191980e-04\n",
      "    1.31827430e-04   1.41068711e-04]\n",
      " [  1.53020286e-04   9.53120703e-04   4.60422551e-03 ...,   1.33011694e-04\n",
      "    1.73591587e-04   1.21558936e-04]]\n",
      "Output 矩阵 shape：\n",
      "(12949, 5001)\n",
      "(5001,)\n",
      "---\n",
      "Probability: 0.002079\n",
      "------\n",
      "Iteration 8\n",
      "Cost 矩阵：\n",
      "[ 8.97271633  9.08995628  9.10838604 ...,  8.83681202  8.44041824\n",
      "  8.24239159]\n",
      "Cost 矩阵 shape：\n",
      "(12949,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  8.99744191e-05   4.05250192e-02   2.51300191e-03 ...,   9.59887693e-05\n",
      "    1.22041791e-04   9.59922545e-05]\n",
      " [  1.14251838e-04   2.98915654e-02   2.01891549e-03 ...,   1.12162605e-04\n",
      "    1.35503826e-04   1.08572887e-04]\n",
      " [  9.35449207e-05   5.42418770e-02   2.57239002e-03 ...,   9.51204929e-05\n",
      "    1.03339502e-04   8.70617150e-05]\n",
      " ..., \n",
      " [  1.25946361e-04   2.14696657e-02   1.72518136e-03 ...,   1.25002174e-04\n",
      "    1.41735669e-04   1.21544530e-04]\n",
      " [  1.25001607e-04   2.65789591e-02   2.12263665e-03 ...,   1.28473039e-04\n",
      "    1.21103272e-04   1.30439701e-04]\n",
      " [  1.42786666e-04   1.83165986e-02   1.46167981e-03 ...,   1.24129700e-04\n",
      "    1.61268312e-04   1.13635477e-04]]\n",
      "Output 矩阵 shape：\n",
      "(12949, 5001)\n",
      "(5001,)\n",
      "---\n",
      "Probability: 0.002785\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.0002).minimize(cost)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dummy_feed_dict = {input_data: inputs_train,\n",
    "                       labels: labels_train}\n",
    "    for i in range(10):\n",
    "        sess.run(train_step, feed_dict=dummy_feed_dict)\n",
    "        if i % 2 == 0:\n",
    "            print(\"Iteration %d\" % i)\n",
    "            \n",
    "            # cost 情况\n",
    "            cost_array = cost.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Cost 矩阵：\")\n",
    "            print(cost_array)\n",
    "            print(\"Cost 矩阵 shape：\")\n",
    "            print(cost_array.shape)\n",
    "            print('---')\n",
    "            \n",
    "            # Output 情况\n",
    "            output_array = output.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Output 矩阵：\")\n",
    "            print(output_array)\n",
    "            print(\"Output 矩阵 shape：\")\n",
    "            print(output_array.shape)\n",
    "            print(output_array[0].shape)\n",
    "            print('---')\n",
    "            \n",
    "            # 查看输出中 ID == 30 的概率            \n",
    "            print(\"Probability: %f\" % output_array[0, 30])\n",
    "            print(\"------\")\n",
    "            # 词向量是 context_embeds 吗？\n",
    "            allwords_embedding = context_embeds.eval(feed_dict=dummy_feed_dict)\n",
    "            raw_outputs = raw_output.eval(feed_dict=dummy_feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算近义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_words(word, top_k=10):\n",
    "    \n",
    "    a = allwords_embedding\n",
    "    id_ = vocab.index(word.decode('utf-8'))\n",
    "    \n",
    "    len_array = np.diag(a.dot(a.T)) ** 0.5\n",
    "    cos_array = a.dot(a[id_]) / len_array\n",
    "    cos_dict = dict(zip(cos_array, words[1:-1]))\n",
    "    sort_cos_dict = sorted(cos_dict.items(), key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    \n",
    "    return sort_cos_dict#[0:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11250"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.07938 大道\n",
      "6.63646 人生\n",
      "6.62324 至此\n",
      "6.6072 苔藓\n",
      "6.58557 独角\n",
      "6.55789 再\n",
      "6.55259 方法\n",
      "6.53961 会\n",
      "6.53853 怎么\n",
      "6.53549 起伏\n"
     ]
    }
   ],
   "source": [
    "result = sim_words('三藏')\n",
    "for k,v in result[0:10]:\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道 299\n",
      "了 273\n",
      "我 265\n",
      "他 215\n",
      "的 213\n",
      "你 207\n",
      "那 160\n",
      "是 146\n",
      "三藏 139\n",
      "行者 117\n",
      "有 115\n",
      "去 95\n",
      "这 92\n",
      "又 92\n",
      "来 90\n",
      "也 84\n",
      "在 83\n",
      "不 76\n",
      "师父 70\n",
      "见 65\n",
      "得 65\n",
      "就 53\n",
      "与 53\n",
      "着 51\n",
      "个 50\n",
      "一 49\n",
      "菩萨 46\n",
      "说 45\n",
      "却 45\n",
      "上 43\n"
     ]
    }
   ],
   "source": [
    "for w,c in vocab2[0:30]:\n",
    "    print(\"%s %d\" % (w, c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
