{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import jieba\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 决定了 embedding 的维度 （隐层节点数）\n",
    "word_embedding_dim = 30\n",
    "# 决定了词表数量, 预留一个未登录词\n",
    "vocab_size = 400 + 1\n",
    "UNK_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "input_data = tf.placeholder(tf.int32, shape=[None, 2], name='input_data')\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词向量相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_embeds = tf.reduce_sum(input_embeds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 映射到 N 个词的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_output 是一个 vocab_size 维的数据，对比 labels 计算 cost\n",
    "# 假设输入一组（也就是 两个词），输出因为词向量相加过了，所以就是一个词的词向量：one-hot？\n",
    "raw_output = tf.layers.dense(context_embeds, vocab_size)\n",
    "# 如果输入一组，输出的 softmax 是预测的 one-hot 的概率分布？最可能的那个输出词概率最大？\n",
    "output = tf.nn.softmax(raw_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 样本的 labels 也需要用 placeholder 放置\n",
    "labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "# 因为我们每个样本的 label 只有一个，使用稠密的 softmax 算 cost 及求导太浪费了。这里使用 sparse 版本即可。\n",
    "# 如果你的 label 是完整的 N 个词上的概率分布，这时候可以使用 tf.nn.softmax_cross_entropy_with_logits\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=raw_output, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 记录器记录 cost\n",
    "# scalar 标量，只能是一个值\n",
    "# 实际 run 时才会记录\n",
    "cost_summary = tf.summary.scalar('cost', cost[0])\n",
    "\n",
    "# mearge 会自动收集 graph 上所有 summary 操作\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取语料，生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "line_no = 0\n",
    "words = []\n",
    "with open('../AssisantEvaluate/xiyouji.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line_no += 1\n",
    "        if line_no > 500:\n",
    "            break\n",
    "        word = pseg.cut(line.strip().decode('utf-8')) # 去掉末尾的 '\\n'\n",
    "        for w,f in word:\n",
    "            if f == 'x':\n",
    "                continue\n",
    "            words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 统计词频\n",
    "word_cnt = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 高频截断\n",
    "vocab = [i[0] for i in word_cnt.most_common(vocab_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 插入未登录词\n",
    "vocab.insert(UNK_IDX, 'UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 映射 id\n",
    "word_ids = [vocab.index(word) if (word in vocab) else 0\n",
    "            for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "inputs_train = np.asarray(\n",
    "                [[word_ids[i-1], word_ids[i+1]] for i in range(1, len(word_ids) - 1)])\n",
    "labels_train = np.asarray(word_ids[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6152, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6152,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Cost 矩阵：\n",
      "[  2.38418306e-06   2.38418306e-06   2.38418306e-06 ...,   1.59696875e+01\n",
      "   1.68130569e+01   4.89938175e-05]\n",
      "Cost 矩阵 shape：\n",
      "(6152,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  9.99997616e-01   8.77733797e-09   2.72109126e-08 ...,   3.30780847e-09\n",
      "    9.76009318e-09   4.16823553e-09]\n",
      " [  9.99997616e-01   8.77733797e-09   2.72109126e-08 ...,   3.30780847e-09\n",
      "    9.76009318e-09   4.16823553e-09]\n",
      " [  9.99997616e-01   8.77733797e-09   2.72109126e-08 ...,   3.30780847e-09\n",
      "    9.76009318e-09   4.16823553e-09]\n",
      " ..., \n",
      " [  9.99949932e-01   1.42101385e-07   3.94511545e-07 ...,   7.75119489e-08\n",
      "    1.17301809e-07   8.61246789e-08]\n",
      " [  9.99992013e-01   3.64212589e-08   9.25997838e-08 ...,   1.29983695e-08\n",
      "    3.77883467e-08   1.65706524e-08]\n",
      " [  9.99951005e-01   1.26544151e-07   3.05970786e-07 ...,   7.12542345e-08\n",
      "    1.22577703e-07   7.54645910e-08]]\n",
      "Output 矩阵 shape：\n",
      "(6152, 401)\n",
      "(401,)\n",
      "---\n",
      "Probability: 0.000000\n",
      "------\n",
      "Iteration 2\n",
      "Cost 矩阵：\n",
      "[ 2.01480889  2.01480889  2.01480889 ...,  7.64883137  6.30210876\n",
      "  0.32969129]\n",
      "Cost 矩阵 shape：\n",
      "(6152,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  1.33345872e-01   3.66216758e-03   4.59818216e-03 ...,   1.62637397e-03\n",
      "    2.44472316e-03   1.78117014e-03]\n",
      " [  1.33345872e-01   3.66216758e-03   4.59818216e-03 ...,   1.62637397e-03\n",
      "    2.44472316e-03   1.78117014e-03]\n",
      " [  1.33345872e-01   3.66216758e-03   4.59818216e-03 ...,   1.62637397e-03\n",
      "    2.44472316e-03   1.78117014e-03]\n",
      " ..., \n",
      " [  7.84715950e-01   2.06335797e-03   3.83647508e-03 ...,   3.21993459e-04\n",
      "    4.67899867e-04   3.52552801e-04]\n",
      " [  4.87976283e-01   3.87545326e-03   5.16276387e-03 ...,   8.11471138e-04\n",
      "    1.65080780e-03   9.58901714e-04]\n",
      " [  7.19145715e-01   2.49037473e-03   3.98045406e-03 ...,   3.97323078e-04\n",
      "    6.47471519e-04   4.12647583e-04]]\n",
      "Output 矩阵 shape：\n",
      "(6152, 401)\n",
      "(401,)\n",
      "---\n",
      "Probability: 0.002936\n",
      "------\n",
      "Iteration 4\n",
      "Cost 矩阵：\n",
      "[  1.51495566e-03   1.51495566e-03   1.51495566e-03 ...,   1.16399221e+01\n",
      "   1.22489214e+01   9.66819189e-03]\n",
      "Cost 矩阵 shape：\n",
      "(6152,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  9.98486221e-01   1.49770412e-05   1.73319513e-05 ...,   2.15982345e-06\n",
      "    4.36785513e-06   2.51938377e-06]\n",
      " [  9.98486221e-01   1.49770412e-05   1.73319513e-05 ...,   2.15982345e-06\n",
      "    4.36785513e-06   2.51938377e-06]\n",
      " [  9.98486221e-01   1.49770412e-05   1.73319513e-05 ...,   2.15982345e-06\n",
      "    4.36785513e-06   2.51938377e-06]\n",
      " ..., \n",
      " [  9.95771110e-01   9.55895448e-05   1.16425857e-04 ...,   6.07721995e-06\n",
      "    8.38779579e-06   6.48713285e-06]\n",
      " [  9.98608291e-01   2.44860694e-05   2.54995612e-05 ...,   1.88171305e-06\n",
      "    4.32902380e-06   2.26978796e-06]\n",
      " [  9.90378380e-01   2.04686337e-04   2.14397791e-04 ...,   1.31331799e-05\n",
      "    2.03045729e-05   1.32634159e-05]]\n",
      "Output 矩阵 shape：\n",
      "(6152, 401)\n",
      "(401,)\n",
      "---\n",
      "Probability: 0.000006\n",
      "------\n",
      "Iteration 6\n",
      "Cost 矩阵：\n",
      "[ 1.86175811  1.86175811  1.86175811 ...,  6.38249683  6.05282259\n",
      "  2.92156935]\n",
      "Cost 矩阵 shape：\n",
      "(6152,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[ 0.15539917  0.00260386  0.00259172 ...,  0.00190531  0.00236423\n",
      "   0.00203683]\n",
      " [ 0.15539917  0.00260386  0.00259172 ...,  0.00190531  0.00236423\n",
      "   0.00203683]\n",
      " [ 0.15539917  0.00260386  0.00259172 ...,  0.00190531  0.00236423\n",
      "   0.00203683]\n",
      " ..., \n",
      " [ 0.12091948  0.03512251  0.03270696 ...,  0.00117526  0.00157027\n",
      "   0.00122539]\n",
      " [ 0.22676744  0.01052348  0.00893858 ...,  0.00132379  0.00234909\n",
      "   0.00151371]\n",
      " [ 0.05384912  0.03487004  0.02800314 ...,  0.00122301  0.00181054\n",
      "   0.00120075]]\n",
      "Output 矩阵 shape：\n",
      "(6152, 401)\n",
      "(401,)\n",
      "---\n",
      "Probability: 0.002609\n",
      "------\n",
      "Iteration 8\n",
      "Cost 矩阵：\n",
      "[ 2.73680568  2.73680568  2.73680568 ...,  6.35071659  5.85585785\n",
      "  9.28189087]\n",
      "Cost 矩阵 shape：\n",
      "(6152,)\n",
      "---\n",
      "Output 矩阵：\n",
      "[[  6.47769421e-02   2.06003594e-03   2.04924494e-03 ...,   2.32234551e-03\n",
      "    2.55517103e-03   2.46496312e-03]\n",
      " [  6.47769421e-02   2.06003594e-03   2.04924494e-03 ...,   2.32234551e-03\n",
      "    2.55517103e-03   2.46496312e-03]\n",
      " [  6.47769421e-02   2.06003594e-03   2.04924494e-03 ...,   2.32234551e-03\n",
      "    2.55517103e-03   2.46496312e-03]\n",
      " ..., \n",
      " [  2.08111043e-04   6.51871189e-02   5.07807210e-02 ...,   1.22386520e-03\n",
      "    1.58239447e-03   1.23704295e-03]\n",
      " [  6.95800735e-03   1.51763791e-02   1.18365744e-02 ...,   1.77039683e-03\n",
      "    2.91247317e-03   1.99066219e-03]\n",
      " [  9.30949027e-05   5.95083125e-02   4.02979851e-02 ...,   1.20207504e-03\n",
      "    1.71432109e-03   1.13952183e-03]]\n",
      "Output 矩阵 shape：\n",
      "(6152, 401)\n",
      "(401,)\n",
      "---\n",
      "Probability: 0.002612\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.0002).minimize(cost)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dummy_feed_dict = {input_data: inputs_train,\n",
    "                       labels: labels_train}\n",
    "    for i in range(10):\n",
    "        #sess.run(train_step, feed_dict=dummy_feed_dict)\n",
    "        _, cost_summary_run = sess.run([train_step, cost_summary], feed_dict=dummy_feed_dict)\n",
    "        writer.add_summary(cost_summary_run, i)\n",
    "        if i % 2 == 0:\n",
    "            print(\"Iteration %d\" % i)\n",
    "            \n",
    "            # cost 情况\n",
    "            cost_array = cost.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Cost 矩阵：\")\n",
    "            print(cost_array)\n",
    "            print(\"Cost 矩阵 shape：\")\n",
    "            print(cost_array.shape)\n",
    "            print('---')\n",
    "            \n",
    "            # Output 情况\n",
    "            output_array = output.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Output 矩阵：\")\n",
    "            print(output_array)\n",
    "            print(\"Output 矩阵 shape：\")\n",
    "            print(output_array.shape)\n",
    "            print(output_array[0].shape)\n",
    "            print('---')\n",
    "            \n",
    "            # 查看输出中 ID == 30 的概率            \n",
    "            print(\"Probability: %f\" % output_array[0, 30])\n",
    "            print(\"------\")\n",
    "            # 词向量是 context_embeds 吗？\n",
    "            allwords_embedding = context_embeds.eval(feed_dict=dummy_feed_dict)\n",
    "            raw_outputs = raw_output.eval(feed_dict=dummy_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7f89c45951d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.FileWriter(\"./tf_log\", graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
