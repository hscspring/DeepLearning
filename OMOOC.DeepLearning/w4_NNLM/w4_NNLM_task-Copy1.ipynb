{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业4\n",
    "\n",
    "请根据这个基本的框架程序进行扩展，使用你的语料库进行训练。并完成 3 个名词各自最相近的 Top 10 个词的检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 决定了 embedding 的维度 （隐层节点数）\n",
    "word_embedding_dim = 50\n",
    "# 决定了词表数量, 预留一个未登录词\n",
    "vocab_size = 5000 + 1\n",
    "UNK_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "input_data = tf.placeholder(tf.int32, shape=[None, 2], name='input_data')\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_data:0' shape=(?, 2) dtype=int32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, 2, 50) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词向量相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context_embeds = tf.reduce_sum(input_embeds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(?, 50) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 映射到 N 个词的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raw_output 是一个 vocab_size 维的数据，对比 labels 计算 cost\n",
    "# 假设输入一组（也就是 两个词），输出因为词向量相加过了，所以就是一个词的词向量：one-hot？\n",
    "raw_output = tf.layers.dense(context_embeds, vocab_size)\n",
    "# 如果输入一组，输出的 softmax 是预测的 one-hot 的概率分布？最可能的那个输出词概率最大？\n",
    "output = tf.nn.softmax(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(?, 5001) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 5001) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 样本的 labels 也需要用 placeholder 放置\n",
    "labels = tf.placeholder(tf.int32, shape=[None], name='labels')\n",
    "\n",
    "# 因为我们每个样本的 label 只有一个，使用稠密的 softmax 算 cost 及求导太浪费了。这里使用 sparse 版本即可。\n",
    "# 如果你的 label 是完整的 N 个词上的概率分布，这时候可以使用 tf.nn.softmax_cross_entropy_with_logits\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=raw_output, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取语料，生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_no = 0\n",
    "words = []\n",
    "with open('../AssisantEvaluate/xiyouji.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line_no += 1\n",
    "        if line_no > 10000:\n",
    "            break\n",
    "        word = pseg.cut(line.strip().decode('utf-8')) # 去掉末尾的 '\\n'\n",
    "        for w,f in word:\n",
    "            if f == 'x':\n",
    "                continue\n",
    "            words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132268"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 统计词频\n",
    "word_cnt = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19387"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 高频截断\n",
    "vocab = [i[0] for i in word_cnt.most_common(vocab_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab2 = [i for i in word_cnt.most_common(vocab_size - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 插入未登录词\n",
    "vocab.insert(UNK_IDX, 'UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 映射 id\n",
    "word_ids = [vocab.index(word) if (word in vocab) else 0 for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132268"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "inputs_train = np.asarray([[word_ids[i-1], word_ids[i+1]] for i in range(1, len(word_ids) - 1)])\n",
    "labels_train = np.asarray(word_ids[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132266, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132266,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.0002).minimize(cost)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dummy_feed_dict = {input_data: inputs_train,\n",
    "                       labels: labels_train}\n",
    "    for i in range(10):\n",
    "        sess.run(train_step, feed_dict=dummy_feed_dict)\n",
    "        if i % 2 == 0:\n",
    "            print(\"Iteration %d\" % i)\n",
    "            \n",
    "            # cost 情况\n",
    "            cost_array = cost.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Cost 矩阵：\")\n",
    "            print(cost_array)\n",
    "            print(\"Cost 矩阵 shape：\")\n",
    "            print(cost_array.shape)\n",
    "            print('---')\n",
    "            \n",
    "            # Output 情况\n",
    "            output_array = output.eval(feed_dict=dummy_feed_dict)\n",
    "            print(\"Output 矩阵：\")\n",
    "            print(output_array)\n",
    "            print(\"Output 矩阵 shape：\")\n",
    "            print(output_array.shape)\n",
    "            print(output_array[0].shape)\n",
    "            print('---')\n",
    "            \n",
    "            # 查看输出中 ID == 30 的概率            \n",
    "            print(\"Probability: %f\" % output_array[0, 30])\n",
    "            print(\"------\")\n",
    "            # 词向量是 context_embeds 吗？\n",
    "            allwords_embedding = context_embeds.eval(feed_dict=dummy_feed_dict)\n",
    "            raw_outputs = raw_output.eval(feed_dict=dummy_feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算近义词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sim_words(word, top_k=10):\n",
    "    \n",
    "    a = allwords_embedding\n",
    "    id_ = vocab.index(word.decode('utf-8'))\n",
    "    \n",
    "    len_array = np.diag(a.dot(a.T)) ** 0.5\n",
    "    cos_array = a.dot(a[id_]) / len_array\n",
    "    cos_dict = dict(zip(cos_array, words[1:-1]))\n",
    "    sort_cos_dict = sorted(cos_dict.items(), key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    \n",
    "    return sort_cos_dict[0:top_k], len(cos_array), len(cos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4270"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(words[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(7.0793791, u'\\u5927\\u9053'),\n",
       "  (6.6364622, u'\\u4eba\\u751f'),\n",
       "  (6.6232367, u'\\u81f3\\u6b64'),\n",
       "  (6.607203, u'\\u82d4\\u85d3'),\n",
       "  (6.5855713, u'\\u72ec\\u89d2'),\n",
       "  (6.5578933, u'\\u518d'),\n",
       "  (6.5525885, u'\\u65b9\\u6cd5'),\n",
       "  (6.539609, u'\\u4f1a'),\n",
       "  (6.5385327, u'\\u600e\\u4e48'),\n",
       "  (6.5354853, u'\\u8d77\\u4f0f')],\n",
       " 12949,\n",
       " 11250)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_words('三藏')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11250"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.07938 大道\n",
      "6.63646 人生\n",
      "6.62324 至此\n",
      "6.6072 苔藓\n",
      "6.58557 独角\n",
      "6.55789 再\n",
      "6.55259 方法\n",
      "6.53961 会\n",
      "6.53853 怎么\n",
      "6.53549 起伏\n"
     ]
    }
   ],
   "source": [
    "result = sim_words('三藏')\n",
    "for k,v in result[0:10]:\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道 299\n",
      "了 273\n",
      "我 265\n",
      "他 215\n",
      "的 213\n",
      "你 207\n",
      "那 160\n",
      "是 146\n",
      "三藏 139\n",
      "行者 117\n",
      "有 115\n",
      "去 95\n",
      "这 92\n",
      "又 92\n",
      "来 90\n",
      "也 84\n",
      "在 83\n",
      "不 76\n",
      "师父 70\n",
      "见 65\n",
      "得 65\n",
      "就 53\n",
      "与 53\n",
      "着 51\n",
      "个 50\n",
      "一 49\n",
      "菩萨 46\n",
      "说 45\n",
      "却 45\n",
      "上 43\n"
     ]
    }
   ],
   "source": [
    "for w,c in vocab2[0:30]:\n",
    "    print(\"%s %d\" % (w, c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
