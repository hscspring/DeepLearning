{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 卷积神经网络用于自然语言处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 2.7.6\n",
      "IPython 5.1.0\n",
      "\n",
      "tensorflow 1.0.1\n",
      "numpy 1.12.1\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.4.0-21-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "# 示例代码运行环境\n",
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "������xp������������������������������������������������������������\t1\r\n",
      "������������,������������,������������������������,������������������.������������.\t1\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 train_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 1000 1000 5.1M Apr 13 06:28 train_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh train_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  24586   42112 5264999 train_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc train_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1M\ttrain_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs train_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls train_shuffle.txt | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r\n"
     ]
    }
   ],
   "source": [
    "!ls train_shuffle.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IGNORE = ' \\n' # 忽略的字符\n",
    "DOC_LENGTH = 50 # 句子预设长度\n",
    "PADDING = '<PD>' # 句子长度不足时的占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_docs_and_labels(file):\n",
    "    \"\"\"从文件读取样本，去除忽略字符，得到句子和标签列表\"\"\"\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    docs, labels = [], []\n",
    "    for line in lines:\n",
    "        text, label = line.decode('utf-8').split('\\t')\n",
    "        \n",
    "        words_in_doc = []\n",
    "        for word in jieba.cut(text):\n",
    "            if (word not in IGNORE) and (not word.isdigit()):\n",
    "                words_in_doc.append(word)\n",
    "        docs.append(words_in_doc)\n",
    "        labels.append(int(label.strip()))\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_doc_length(docs):\n",
    "    \"\"\"将样本所有词列表调整为固定长度\"\"\"\n",
    "    for i in range(len(docs)):\n",
    "        if len(docs[i]) < DOC_LENGTH:\n",
    "            docs[i].extend([PADDING] * (DOC_LENGTH - len(docs[i])))\n",
    "        else:\n",
    "            docs[i] = docs[i][:DOC_LENGTH]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counter(docs):\n",
    "    flat_words = [w for doc in docs for w in doc]\n",
    "    return Counter(flat_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(word_cnt, limit=3):\n",
    "    \"\"\"仅计入出现次数超过 3 的词\"\"\"\n",
    "    vocab = ['UNK']\n",
    "    for word, count in word_cnt.most_common():\n",
    "        if count > limit:\n",
    "            vocab.append(word)\n",
    "        else:\n",
    "            break\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docs2idxes(docs):\n",
    "    \"\"\"将词列表的列表转换为序号列表的列表\"\"\"\n",
    "    idxes = []\n",
    "    for doc in docs:\n",
    "        idxes_of_one_doc = []\n",
    "        for word in doc:\n",
    "            idx = idx_dict[word] if (word in vocab) else 0\n",
    "            idxes_of_one_doc.append(idx)\n",
    "        idxes.append(idxes_of_one_doc)\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_docs, train_labels = read_docs_and_labels('./train_shuffle.txt')\n",
    "test_docs, test_labels = read_docs_and_labels('./test_shuffle.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_docs = fix_doc_length(train_docs)\n",
    "test_docs = fix_doc_length(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_cnt = get_word_counter(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = build_vocab(word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_dict = dict(zip(vocab, range(vocab_size))) # 词映射到序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PD> 475822\n",
      "， 62594\n",
      "的 41658\n",
      "。 22766\n",
      "了 15991\n",
      "是 10897\n",
      ", 10705\n",
      "我 8824\n",
      "很 8072\n",
      "也 6014\n",
      "酒店 5796\n",
      "！ 5677\n",
      "在 5334\n",
      "不 5157\n",
      ". 4714\n",
      "都 4680\n",
      "有 4594\n",
      "就 4288\n",
      "房间 4206\n",
      "没有 4067\n"
     ]
    }
   ],
   "source": [
    "for w, f in word_cnt.most_common(20):\n",
    "    print('%s %s' %(w,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idxes = docs2idxes(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train = np.asarray(train_idxes)\n",
    "labels_train = np.asarray(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_idxes = docs2idxes(test_docs)\n",
    "inputs_test = np.asarray(test_idxes)\n",
    "labels_test = np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24586, 50)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10538, 50)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#vocab_size = 80000\n",
    "word_embed_size = 128\n",
    "#filter_num = 30\n",
    "#window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "随机生成词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, word_embed_size], -1.0, 1.0),\n",
    "                name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.int32, shape=[None, DOC_LENGTH], name='inputs')\n",
    "labels = tf.placeholder(tf.int32, shape=[None], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "根据句子的 ID 查找词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embeds = tf.nn.embedding_lookup(W, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_lookup:0\", shape=(?, 50, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 注意观察 embedding 维度。这里只有一个样本\n",
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 自行查看 expand_dims 的 API 说明。这里是为了适应 conv2d 等参数，拓展了一个维度 (in_channel)，长度是 1\n",
    "embeds_expand = tf.expand_dims(embeds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ExpandDims:0\", shape=(?, 50, 128, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 扩展之后的维度\n",
    "print(embeds_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# max_pool\n",
    "with tf.name_scope(\"conv-maxpool\"):\n",
    "    filter_num = 64\n",
    "    window_size = 3\n",
    "    filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "    # W 和 b 是卷积的参数\n",
    "    W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "    # bias 和 filter_num 个数是一样的\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "    # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding（不加也不影响作业评分）\n",
    "    conv = tf.nn.conv2d(\n",
    "                    embeds_expand,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "    # 卷积出来的结果加上 bias\n",
    "    conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "\n",
    "    # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1，如果加了 padding 这里要对应更改。\n",
    "    pool = tf.nn.max_pool(\n",
    "                    conv_hidden,\n",
    "                    ksize=[1, DOC_LENGTH - window_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "目前 tensorflow 还不支持动态 max_pool size，所以 ksize 只能用常数固定，\n",
    "\n",
    "因为不同句子 sequence_length 不一样，因此目前这里目前还没法做到处理变长句子。\n",
    "    \n",
    "一个解决方案是用人工 Padding 的方式，根据语料中最长的句子的长度来扩展所有句子，归一化到统一的长度。即所有句子都通过 Padding 一个特殊符号的方式，扩展为固定长度。\n",
    "\n",
    "**注意这个是 Tensorflow 目前的限制**，用其他一些支持动态 max_pool 的库不需要 padding。事实上这也会造成计算量的浪费。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "鼓励大家多看中间结果的维度，加深理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv-maxpool/conv:0\", shape=(?, 48, 1, 64), dtype=float32)\n",
      "Tensor(\"conv-maxpool/tanh:0\", shape=(?, 48, 1, 64), dtype=float32)\n",
      "Tensor(\"conv-maxpool/pool:0\", shape=(?, 1, 1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(conv)\n",
    "print(conv_hidden)\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "卷积 + max pooling 之后的结果可以再接 dense layer (全连接层）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "根据这个框架改成符合作业要求的脚本，用于情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squeezed_pool = tf.squeeze(pool, [1, 2]) \n",
    "# fc = tf.layers.dense(pool, num_fc_hidden, activation=tf.nn.tanh)\n",
    "raw_output = tf.layers.dense(squeezed_pool, 2)\n",
    "output = tf.nn.softmax(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2)])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=raw_output, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(sess, inputs_, labels_, print_matrix=False):\n",
    "    \"\"\"评估模型指标，并打印输出\"\"\"\n",
    "    pred_prob = sess.run(output, feed_dict={inputs:inputs_, labels:labels_})\n",
    "    preds = np.asarray((pred_prob[:, 1] > 0.5), dtype=int)\n",
    "    mat = sess.run(tf.confusion_matrix(labels_, preds))\n",
    "    tn, fp, fn,  tp = mat.reshape(4)\n",
    "    precision = np.float(tp) / (tp + fp)\n",
    "    recall = np.float(tp) / (tp + fn)\n",
    "    if print_matrix:\n",
    "        print('confusion matrix:\\n', mat)\n",
    "    print('precision:% .3f, recall: %.3f' %(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost: train: 0.84746 / test: 0.849917\n",
      "precision: 0.469, recall: 0.983\n",
      "Epoch 100 cost: train: 0.0132941 / test: 0.917752\n",
      "precision: 0.885, recall: 0.882\n",
      "Epoch 200 cost: train: 0.0108253 / test: 1.04141\n",
      "precision: 0.886, recall: 0.888\n",
      "Epoch 300 cost: train: 0.00827338 / test: 1.09468\n",
      "precision: 0.888, recall: 0.884\n",
      "Epoch 400 cost: train: 0.00807151 / test: 1.13787\n",
      "precision: 0.889, recall: 0.884\n",
      "Epoch 500 cost: train: 0.00729369 / test: 1.17622\n",
      "precision: 0.890, recall: 0.883\n",
      "Epoch 600 cost: train: 0.00712899 / test: 1.21371\n",
      "precision: 0.890, recall: 0.881\n",
      "Epoch 700 cost: train: 0.0064577 / test: 1.22829\n",
      "precision: 0.890, recall: 0.879\n",
      "Epoch 800 cost: train: 0.00636252 / test: 1.24298\n",
      "precision: 0.892, recall: 0.880\n",
      "Epoch 900 cost: train: 0.00632875 / test: 1.24938\n",
      "precision: 0.891, recall: 0.881\n",
      "Epoch 1000 cost: train: 0.0062647 / test: 1.25138\n",
      "precision: 0.891, recall: 0.881\n",
      "Epoch 1100 cost: train: 0.00611953 / test: 1.248\n",
      "precision: 0.891, recall: 0.881\n",
      "Epoch 1200 cost: train: 0.00627607 / test: 1.24744\n",
      "precision: 0.890, recall: 0.881\n",
      "Epoch 1300 cost: train: 0.00609229 / test: 1.24058\n",
      "precision: 0.890, recall: 0.881\n",
      "Epoch 1400 cost: train: 0.00581472 / test: 1.2352\n",
      "precision: 0.889, recall: 0.879\n",
      "Epoch 1500 cost: train: 0.00572355 / test: 1.23145\n",
      "precision: 0.890, recall: 0.879\n",
      "Epoch 1600 cost: train: 0.00556987 / test: 1.22778\n",
      "precision: 0.890, recall: 0.879\n",
      "Epoch 1700 cost: train: 0.00553212 / test: 1.22601\n",
      "precision: 0.889, recall: 0.880\n",
      "Epoch 1800 cost: train: 0.00553181 / test: 1.22583\n",
      "precision: 0.889, recall: 0.879\n",
      "Epoch 1900 cost: train: 0.00552977 / test: 1.22569\n",
      "precision: 0.890, recall: 0.879\n",
      "Epoch 2000 cost: train: 0.00508532 / test: 1.22904\n",
      "precision: 0.890, recall: 0.880\n",
      "Epoch 2100 cost: train: 0.00508804 / test: 1.23906\n",
      "precision: 0.890, recall: 0.880\n",
      "Epoch 2200 cost: train: 0.00509093 / test: 1.24549\n",
      "precision: 0.891, recall: 0.880\n",
      "Epoch 2300 cost: train: 0.00508532 / test: 1.25459\n",
      "precision: 0.890, recall: 0.881\n",
      "Epoch 2400 cost: train: 0.00508045 / test: 1.25739\n",
      "precision: 0.891, recall: 0.882\n",
      "Epoch 2500 cost: train: 0.00506766 / test: 1.26098\n",
      "precision: 0.891, recall: 0.881\n",
      "Epoch 2600 cost: train: 0.00506561 / test: 1.26311\n",
      "precision: 0.891, recall: 0.881\n",
      "Epoch 2700 cost: train: 0.00505735 / test: 1.26404\n",
      "precision: 0.892, recall: 0.881\n",
      "Epoch 2800 cost: train: 0.00480461 / test: 1.26742\n",
      "precision: 0.891, recall: 0.880\n",
      "Epoch 2900 cost: train: 0.00479508 / test: 1.27586\n",
      "precision: 0.891, recall: 0.880\n",
      "\n",
      "time: 31036.834903\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "batch_size = 100\n",
    "epochs = 3000\n",
    "print_cost_every = 100\n",
    "\n",
    "feed_train = {inputs: inputs_train, labels: labels_train}\n",
    "feed_test = {inputs: inputs_test, labels: labels_test}\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "costs_train = []\n",
    "costs_test = []\n",
    "start_time = time.time()\n",
    "\n",
    "num_inputs = len(labels_train)\n",
    "order = np.arange(num_inputs)\n",
    "np.random.shuffle(order)\n",
    "\n",
    "try:\n",
    "    for i in range(epochs):\n",
    "        if i % print_cost_every == 0:\n",
    "            cost_train = sess.run(cost, feed_dict=feed_train)\n",
    "            cost_test = sess.run(cost, feed_dict=feed_test)\n",
    "            print('Epoch %d cost: train: %s / test: %s' %(i, cost_train, cost_test))\n",
    "            costs_train.append(cost_train)\n",
    "            costs_test.append(cost_test)\n",
    "            evaluate_model(sess, inputs_test, labels_test)\n",
    "        for j in range(0, num_inputs, batch_size):\n",
    "            batch_index = order[j: j + batch_size]\n",
    "            batch_inputs = inputs_train[batch_index]\n",
    "            batch_labels = labels_train[batch_index]\n",
    "            batch_feed = {inputs: batch_inputs, labels: batch_labels}\n",
    "            sess.run(train_step, feed_dict=batch_feed)\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    print('\\ntime: %s' % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
