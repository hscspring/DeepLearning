{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "word_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i: i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.asarray(list(chunks(range(30), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x7fbce9f10390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(10, 2, 128) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data[:, [0, 1]])\n",
    "input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'rnn/transpose:0' shape=(10, 2, 128) dtype=float32>, <tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 128) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# 这里 states 就是 output\n",
    "# 也可以做更复杂的模型\n",
    "# 本例中，前进了两步，会有两个输出，就是两个 state\n",
    "# final state 和第二个 output 一样的\n",
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32)\n",
    "print(output, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_flat = tf.reshape(output, (-1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 128)\n",
      "(10, 2, 128)\n",
      "(20, 128)\n",
      "(10, 128)\n",
      "[[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " ..., \n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_val = output.eval()\n",
    "    states_val = states.eval()\n",
    "    \n",
    "    print(output_flat.eval().shape) # 20*128\n",
    "    print(output_val.shape) # 10*2*128\n",
    "    # -1 让它自己算维度，也可以直接指定 20\n",
    "    # 必须保证 reshape 后的形状和原来一样\n",
    "    # 128 这个维度是不变的\n",
    "    print(output_val.reshape((-1, 128)).shape) # 20*128\n",
    "    \n",
    "    print(states_val.shape) # 10*128\n",
    "    \n",
    "    print(output_val[:,1,:] == states_val)\n",
    "    # 确定是不是每一个都是 True\n",
    "    print((output_val[:,1,:] == states_val).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变长数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [1, 2, 3], [1, 2, 3, 4, 5]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 三个样本，句子长度分别是 2 3 5\n",
    "data = [[1, 2], [1, 2, 3], [1, 2, 3, 4, 5]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0, 0],\n",
       "       [1, 2, 3, 0, 0],\n",
       "       [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding，补 0\n",
    "data_padding= np.asarray([[1, 2, 0, 0, 0], [1, 2, 3, 0, 0], [1, 2, 3, 4, 5]])\n",
    "data_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "word_embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(128)\n",
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(3, 4, 128) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去掉了最后一个词，对网络来说，不需要最后一个词\n",
    "# 最后一个词作为 label 训练的\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data_padding[:, 0:4])\n",
    "input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0 0]\n",
      " [1 2 3 0]\n",
      " [1 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(data_padding[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 虽然给的数据是 padding 过的，但是 sequence_length 可以自动停止进化\n",
    "# 它超过长度后，state 就一直复制上一个结果，output 就置为 0\n",
    "# 只是简单复制，对性能影响也很小\n",
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32, sequence_length=[2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加了 sequence_length 参数是一个 Tensor（可以随着 batch 的数据变化）  \n",
    "- 对每个样本，超过其对应 sequence_length 之后，dynamic_rnn 不会实际去做 state 计算，而是直接复制上一个 state，超长的对应 output 则设置为 0 向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上面的解释我们知道可以让 dynamic_rnn 在超长之后不做实际计算，这时候超长的部分 output 会输出 0  \n",
    "但是这些 output 仍然会和 label（非零部分才是真正的 label）进行计算，产生 cost，进而影响模型的变量  \n",
    "所以要把 0 的部分的 label 在 cost 函数中去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0],\n",
       "       [2, 3, 0, 0],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding[:, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是我们这个 RNN Language Model 对应的 labels，我们如何让 0 的部分不计入损失呢？  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(12,) dtype=int64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 在用之前会用 reshape 打平成固定长度的行向量\n",
    "labels = tf.reshape(data_padding[:, 1:5], [-1])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sign:0' shape=(12,) dtype=int64>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >0 返回 1，否则 0\n",
    "mask = tf.sign(labels)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tf.sign([-2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(mask.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把原来的 cost 和 mask 函数相乘，结果做 reduce_mean，作为新的 cost 给优化器进行优化，就把不想要的 label 置为 0，即可忽略这些无用的 labels，不会影响最后的 cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 用于生成时的一些提示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell 的 zero_state 函数可以产生该 cell 的初始状态（对 BasicRNNCell 来说就是一个 0 矩阵） cell 本身也可以调用（Python 里的 call 方法，用于产生单步的状态变化）  \n",
    "\n",
    "tf.slice 可以用于取 tensor 的某一列等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "vocab_size = 100\n",
    "word_embedding_dim = 128\n",
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, data_padding[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(4), Dimension(128)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Slice:0\", shape=(3, 1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## 取第一个词\n",
    "single_input_embeds = tf.slice(input_embeds, [0, 0, 0], [3, 1, 128])\n",
    "print(single_input_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 走一步\n",
    "output, state = cell(tf.reshape(single_input_embeds, (3, 128)), cell.zero_state(3, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output_val = output.eval()\n",
    "    state_val = state.eval()\n",
    "    print((output_val == state_val).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
