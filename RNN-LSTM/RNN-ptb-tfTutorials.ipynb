{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#reader\" data-toc-modified-id=\"reader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>reader</a></span><ul class=\"toc-item\"><li><span><a href=\"#reader-细节解读\" data-toc-modified-id=\"reader-细节解读-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>reader 细节解读</a></span></li><li><span><a href=\"#tf.strided_slice\" data-toc-modified-id=\"tf.strided_slice-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>tf.strided_slice</a></span></li><li><span><a href=\"#reader-输出结果\" data-toc-modified-id=\"reader-输出结果-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>reader 输出结果</a></span></li></ul></li><li><span><a href=\"#ptb-word-lm\" data-toc-modified-id=\"ptb-word-lm-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>ptb-word-lm</a></span><ul class=\"toc-item\"><li><span><a href=\"#dropout\" data-toc-modified-id=\"dropout-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>dropout</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方文档，学习的好例子。  \n",
    "[Recurrent Neural Networks  |  TensorFlow](https://www.tensorflow.org/tutorials/recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reader 细节解读"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入的就是 数字 id，one-hot\n",
    "raw_data = np.array([random.randint(1,1000) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([545, 566, 656, 363, 311,  48, 885, 359, 653, 441, 558, 199, 260,\n",
       "       741, 880, 263, 923, 127, 319, 667], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id 转 tensor\n",
    "raw_data = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.int32)\n",
    "sess.run(raw_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.size，展开后数据大小\n",
    "data_len = tf.size(raw_data)\n",
    "sess.run(data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个 batch 有多少数据\n",
    "batch_size = 8 # batch 数量，批大小\n",
    "batch_len = data_len // batch_size\n",
    "sess.run(batch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, ?)\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([545, 566, 656, 363, 311,  48, 885, 359, 653, 441, 558, 199, 260,\n",
       "       741, 880, 263, 923, 127, 319, 667, 332, 537, 898, 166, 587, 303,\n",
       "       871, 454, 786, 832, 380, 376,  59, 990, 664,  78, 906, 355, 906,\n",
       "       287, 568, 507, 333, 903, 273, 429, 503, 670, 900, 788, 128, 136,\n",
       "       379, 138, 321, 439, 993, 609, 800, 207, 518,  98, 548, 620,  84,\n",
       "       441, 602, 575, 357, 420, 833, 439, 760, 143, 371, 212, 418, 597,\n",
       "        40, 210, 770, 403,  25, 208, 266, 269, 199, 992, 765, 280, 821,\n",
       "       977, 306, 296, 312, 353,  44, 361, 203, 252, 341, 859, 186, 974,\n",
       "       718,  54, 612, 249, 389,  17, 767, 137, 654, 271, 470, 235,  73,\n",
       "       192, 625, 386, 906,  83, 166,  72,  54], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一列是一个 batch\n",
    "data = tf.reshape(raw_data[0 : batch_size * batch_len], [batch_size, batch_len])\n",
    "print(data.shape)\n",
    "print(sess.run(batch_size * batch_len))\n",
    "sess.run(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time_step = num_step\n",
    "num_steps = 20\n",
    "epoch_size = (batch_len - 1) // num_steps\n",
    "sess.run(epoch_size) # 6 个 epoch 构成一个 batch， 20 * 6 = 120\n",
    "# 也就是 6 个 epoch 才能把一个 batch 跑完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_producer_Dequeue:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'StridedSlice:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.strided_slice(data, [0, i*num_steps], [batch_size, (i+1)*num_steps])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(8), Dimension(20)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.set_shape([batch_size, num_steps])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.strided_slice(data, [0, i * num_steps + 1],\n",
    "                     [batch_size, (i + 1) * num_steps + 1])\n",
    "y.set_shape([batch_size, num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(8), Dimension(20)])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.strided_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([[[1, 1, 1], [2, 2, 2]],[[3, 3, 3], [4, 4, 4]], [[5, 5, 5], [6, 6, 6]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1],\n",
       "        [2, 2, 2]],\n",
       "\n",
       "       [[3, 3, 3],\n",
       "        [4, 4, 4]],\n",
       "\n",
       "       [[5, 5, 5],\n",
       "        [6, 6, 6]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2 保证 [[3,3,3],[4,4,4]] \n",
    "# 0,1 保证 [3,3,3]\n",
    "# 2,3 保证 [3]\n",
    "sess.run(tf.strided_slice(input, [1, 0, 2], [2, 1, 3], [1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2 保证 [[3,3,3],[4,4,4]] \n",
    "# 0,1 保证 [3,3,3]\n",
    "# 0,3 保证 [3,3,3]\n",
    "sess.run(tf.strided_slice(input, [1, 0, 0], [2, 1, 3], [1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 3, 3],\n",
       "        [4, 4, 4]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2 保证 [[3,3,3],[4,4,4]] \n",
    "# 0,2 保证 [[3,3,3],[4,4,4]] \n",
    "# 0,3 保证 [[3,3,3],[4,4,4]] \n",
    "sess.run(tf.strided_slice(input, [1, 0, 0], [2, 2, 3], [1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 4, 4],\n",
       "        [3, 3, 3]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2 保证 [[3,3,3],[4,4,4]] \n",
    "# -1,-3 保证 [[4,4,4],[3,3,3]] \n",
    "# 0,3 保证 [[4,4,4],[3,3,3]] \n",
    "sess.run(tf.strided_slice(input, [1, -1, 0], [2, -3, 3], [1, -1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reader 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Py3 = sys.version_info[0] == 3\n",
    "\n",
    "def _read_words(filename):\n",
    "  with tf.gfile.GFile(filename, \"r\") as f:\n",
    "    if Py3:\n",
    "      return f.read().replace(\"\\n\", \"<eos>\").split()\n",
    "    else:\n",
    "      return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
    "\n",
    "\n",
    "def _build_vocab(filename):\n",
    "  data = _read_words(filename)\n",
    "\n",
    "  counter = collections.Counter(data)\n",
    "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "  words, _ = list(zip(*count_pairs))\n",
    "  word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "  return word_to_id\n",
    "\n",
    "\n",
    "def _file_to_word_ids(filename, word_to_id):\n",
    "  data = _read_words(filename)\n",
    "  return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "\n",
    "def ptb_raw_data(data_path=None):\n",
    "  train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
    "  valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
    "  test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
    "\n",
    "  word_to_id = _build_vocab(train_path)\n",
    "  train_data = _file_to_word_ids(train_path, word_to_id)\n",
    "  valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
    "  test_data = _file_to_word_ids(test_path, word_to_id)\n",
    "  vocabulary = len(word_to_id)\n",
    "  return train_data, valid_data, test_data, vocabulary\n",
    "\n",
    "\n",
    "def ptb_producer(raw_data, batch_size, num_steps, name=None):\n",
    "  with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):\n",
    "    raw_data = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.int32)\n",
    "\n",
    "    data_len = tf.size(raw_data)\n",
    "    batch_len = data_len // batch_size\n",
    "    data = tf.reshape(raw_data[0 : batch_size * batch_len],\n",
    "                      [batch_size, batch_len])\n",
    "\n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "    assertion = tf.assert_positive(\n",
    "        epoch_size,\n",
    "        message=\"epoch_size == 0, decrease batch_size or num_steps\")\n",
    "    with tf.control_dependencies([assertion]):\n",
    "      epoch_size = tf.identity(epoch_size, name=\"epoch_size\")\n",
    "\n",
    "    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
    "    x = tf.strided_slice(data, [0, i * num_steps],\n",
    "                         [batch_size, (i + 1) * num_steps])\n",
    "    x.set_shape([batch_size, num_steps])\n",
    "    y = tf.strided_slice(data, [0, i * num_steps + 1],\n",
    "                         [batch_size, (i + 1) * num_steps + 1])\n",
    "    y.set_shape([batch_size, num_steps])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = ptb_raw_data(\"./ptb/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, _ = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929589, 73760, 82430)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = _build_vocab('./ptb/data/ptb.train.txt')\n",
    "id2word = dict(zip(word2id.values(), word2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workers exposed to it more than N years ago researchers reported <eos> the asbestos fiber <unk> is unusually <unk> once'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([id2word[w] for w in train_data[100:120]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共多少个 batch： 1327\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20 # batch 的 大小\n",
    "num_steps = 35 # time_step 35，每个 batch 中，每行数据的长度\n",
    "epoch_size = ((len(train_data) // batch_size) - 1) // num_steps # 多少个 batch，一个 epoch\n",
    "print(\"一共多少个 batch：\", epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, targets = ptb_producer(train_data, batch_size, num_steps, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'PTBProducer/StridedSlice:0' shape=(20, 35) dtype=int32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 个 batch 的矩阵数据，每个 batch 35 维，跑 1327 次\n",
    "# 有一点反直觉。。。\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "yam_train = \"The core of the model consists of an LSTM cell that processes one word at a time \\\n",
    "and computes probabilities of the possible values for the next word in the sentence. \\\n",
    "The memory state of the network is initialized with a vector of zeros and gets updated after \\\n",
    "reading each word. For computational reasons, we will process data in mini batches of size batch size. \\\n",
    "In this example, it is important to note that current batch of words does not correspond to \\\n",
    "a sentence of words. Every word in a batch should correspond to a time t. TensorFlow will \\\n",
    "automatically sum the gradients of each batch for you.\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_steps = 5\n",
    "data_len = len(yam_train)\n",
    "batch_len = data_len // batch_size\n",
    "data = tf.reshape(yam_train[0 : batch_size * batch_len],\n",
    "                  [batch_size, batch_len])\n",
    "\n",
    "epoch_size = (batch_len - 1) // num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_5:0' shape=(8, 13) dtype=string>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.strided_slice(data, [0, i * num_steps], [batch_size, (i + 1) * num_steps])\n",
    "x.set_shape([batch_size, num_steps])\n",
    "y = tf.strided_slice(data, [0, i * num_steps + 1],[batch_size, (i + 1) * num_steps + 1])\n",
    "y.set_shape([batch_size, num_steps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'The', b'core', b'of', b'the', b'model'],\n",
       "       [b'word', b'at', b'a', b'time', b'and'],\n",
       "       [b'next', b'word', b'in', b'the', b'sentence.'],\n",
       "       [b'with', b'a', b'vector', b'of', b'zeros'],\n",
       "       [b'computational', b'reasons,', b'we', b'will', b'process'],\n",
       "       [b'In', b'this', b'example,', b'it', b'is'],\n",
       "       [b'does', b'not', b'correspond', b'to', b'a'],\n",
       "       [b'should', b'correspond', b'to', b'a', b'time']], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = 0\n",
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'consists', b'of', b'an', b'LSTM', b'cell'],\n",
       "       [b'computes', b'probabilities', b'of', b'the', b'possible'],\n",
       "       [b'The', b'memory', b'state', b'of', b'the'],\n",
       "       [b'and', b'gets', b'updated', b'after', b'reading'],\n",
       "       [b'data', b'in', b'mini', b'batches', b'of'],\n",
       "       [b'important', b'to', b'note', b'that', b'current'],\n",
       "       [b'sentence', b'of', b'words.', b'Every', b'word'],\n",
       "       [b't.', b'TensorFlow', b'will', b'automatically', b'sum']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = 1\n",
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ptb-word-lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "size = hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embedding\", reuse=True):\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, size], dtype=tf.float16)\n",
    "inputs = tf.nn.embedding_lookup(embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup_1:0' shape=(20, 35, 128) dtype=float16>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [4., 5.],\n",
       "       [6., 7.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2.,3.],[4.,5.],[6.,7.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [4., 5.],\n",
       "       [6., 7.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.dropout(tf.convert_to_tensor(X), keep_prob=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22222222, 3.33333333],\n",
       "       [4.44444444, 5.55555556],\n",
       "       [6.66666667, 7.77777778]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.dropout(tf.convert_to_tensor(X), keep_prob=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5 , 3.75],\n",
       "       [5.  , 0.  ],\n",
       "       [0.  , 8.75]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.dropout(tf.convert_to_tensor(X), keep_prob=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*1/0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
