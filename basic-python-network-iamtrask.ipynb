{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Neural Network in 11 lines of Python (Part 1) - i am trask](http://iamtrask.github.io/2015/07/12/basic-python-network/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "    l1 = 1/(1+np.exp(-(np.dot(X,syn0))))\n",
    "    l2 = 1/(1+np.exp(-(np.dot(l1,syn1))))\n",
    "    l2_delta = (y-l2)*(l2*(1-l2))\n",
    "    l1_delta = l2_delta.dot(syn1.T) * (l1*(1-l1))\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += X.T.dot(l1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: A Tiny Toy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00966449]\n",
      " [ 0.00786506]\n",
      " [ 0.99358898]\n",
      " [ 0.99211957]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def  nonlin(x, deriv=False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "X = np.array([  [0,0,1], \n",
    "                [0,1,1], \n",
    "                [1,0,1], \n",
    "                [1,1,1]  ])\n",
    "\n",
    "\n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "# 权重矩阵大 size 由输入和输出的个数确定，也可以用 l0 和 l1 的 size 确定\n",
    "# 初始化权重 W 矩阵\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    "\n",
    "for iter in range(10000):\n",
    "    # l1 是预测值\n",
    "    # full batch (4 个 samples 一次用上)\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    \n",
    "    # 误差\n",
    "    l1_error = y - l1\n",
    "    \n",
    "    # (y-l1) * l1* (1-l1)；误差 × 导数（ sigmoid 的导函数：y(1-y)\n",
    "    # 更新的系数\n",
    "    l1_delta = l1_error * nonlin(l1, True)\n",
    "    \n",
    "    # 根据输入 X 和 更新系数，更新权重 W 矩阵；y 和 l1 越接近（预测的越准），系数权重越不需要更新（其实可以理解为更新的是输入的 X）\n",
    "    syn0 += np.dot(l0.T,l1_delta)\n",
    "        \n",
    "print (l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlin(l1,True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34093502],\n",
       "       [-0.1653904 ],\n",
       "       [ 0.11737966]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.random.random((3,1)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Slightly Harder Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.536660920155\n",
      "Error:0.500331174315\n",
      "Error:0.500206235232\n",
      "Error:0.500159662229\n",
      "Error:0.500134253787\n",
      "Error:0.500117871151\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if (deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([  [0,0,1], \n",
    "                [0,1,1], \n",
    "                [1,0,1], \n",
    "                [1,1,1]  ])\n",
    "\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# 随机初始化 W （零均值）\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in range(60000):\n",
    "    \n",
    "    # Feed forward through layers 0, 1, and 2\n",
    "    # X full_batch 4*3；如果是 single，那就是 1*3，表示 3 个神经元在 l0 也就是输入层\n",
    "    # l1 4*4；如果是 single，那就是 1*4，表示 4 个神经元在 l1 也就是隐层 1\n",
    "    # l2 4*1；如果是 single，那就是 1*1，表示 1 个神经元在 l2 也就是输出层\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0, syn0))\n",
    "    l2 = nonlin(np.dot(l1, syn1))\n",
    "    \n",
    "    # how much did we miss the target value?\n",
    "    # l2 4*1；le_error 4*1；如果是 single，那就是 1*1，表示 1 个神经元，也就是一个输出（预测值）和训练集的误差\n",
    "    l2_error = y - l2\n",
    "    \n",
    "    if (j%10000) == 0:\n",
    "        print (\"Error:\" + str(np.mean(np.abs(l2-l2_error))))\n",
    "    \n",
    "    # 反向传播，矩阵都是反过来乘：\n",
    "    # 开始反向传播！\n",
    "    # 先从输出层开始！\n",
    "    \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much\n",
    "    # l2_delta 4*1；如果是 single，也就是 1*1，表示更新的大小；来自 输出层 error\n",
    "    # l2_delta 更新的是 l1_error 和 syn1，也就是说更新了隐层的误差和隐层与输出层之间的权重矩阵；它自己在输出层，往回退\n",
    "    # 这玩意儿可以理解为更新后的 l2\n",
    "    l2_delta = l2_error * nonlin(l2, deriv=True) # = l2_error * (l2 * (1-l2)) 导数（梯度）× error\n",
    "    \n",
    "    \n",
    "    # --------------------------***-------------------\n",
    "    \n",
    "    # 反向传播计算 隐层 Error！\n",
    "    \n",
    "    # l1_error 4*4；如果是 single，也就是 1*4，也就是 隐层 输出值的误差\n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    # 反向传播更新！\n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much\n",
    "    # l1_delta 4*4；如果是 single，也就是 1*4，表示更新的大小；来自 隐层 error\n",
    "    # l1_delta 更新的是 syn0，也就是说更新了输入层和隐层之间的权重矩阵，l0_error 不存在，l0 是输入的 X；它自己在隐层，往回退\n",
    "    # 这玩意儿就可以理解为更新后的 l1\n",
    "    l1_delta = l1_error * nonlin(l1, deriv=True)\n",
    "    \n",
    "    # 调整权重矩阵 W\n",
    "    # 隐层和输出层之间的调整，syn1 (4*4)*(4*1)=4*1；如果是 single，那也是 (4*1)*(1*1)=4*1，每个值均做了调整\n",
    "    # 输入层和隐层之间的调整，syn0 (3*4)*(4*4)=3*4；如果是 single，那也是 (3*1)*(1*4)=3*4，每个值均做了调整\n",
    "    # 权重矩阵 shape 不变！\n",
    "    # 用更新后的 l2, l1 更新权重矩阵\n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    \n",
    "    # -----------***-------------\n",
    "    # 正向（前向）传播时，l1 = nonlin(np.dot(l0, syn0))\n",
    "    # 反向（后向）传播时，l0.dot(syn0) = l0.dot(l0.T).dot(l1_delta)\n",
    "    # l0.dot(l0.T) 是一个方阵，与 l1_delta 一起对 l1 本身做了调整（迭代调整）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
