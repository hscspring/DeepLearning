{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#自编码器和多层感知机\" data-toc-modified-id=\"自编码器和多层感知机-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>自编码器和多层感知机</a></div><div class=\"lev2 toc-item\"><a href=\"#自编码器\" data-toc-modified-id=\"自编码器-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>自编码器</a></div><div class=\"lev3 toc-item\"><a href=\"#特征的稀疏表达\" data-toc-modified-id=\"特征的稀疏表达-111\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>特征的稀疏表达</a></div><div class=\"lev3 toc-item\"><a href=\"#自编码器\" data-toc-modified-id=\"自编码器-112\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>自编码器</a></div><div class=\"lev3 toc-item\"><a href=\"#基于深度信念网络（DBN）\" data-toc-modified-id=\"基于深度信念网络（DBN）-113\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>基于深度信念网络（DBN）</a></div><div class=\"lev3 toc-item\"><a href=\"#自编码器的限制\" data-toc-modified-id=\"自编码器的限制-114\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>自编码器的限制</a></div><div class=\"lev4 toc-item\"><a href=\"#L1-正则\" data-toc-modified-id=\"L1-正则-1141\"><span class=\"toc-item-num\">1.1.4.1&nbsp;&nbsp;</span>L1 正则</a></div><div class=\"lev4 toc-item\"><a href=\"#加噪声\" data-toc-modified-id=\"加噪声-1142\"><span class=\"toc-item-num\">1.1.4.2&nbsp;&nbsp;</span>加噪声</a></div><div class=\"lev3 toc-item\"><a href=\"#小结\" data-toc-modified-id=\"小结-115\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>小结</a></div><div class=\"lev2 toc-item\"><a href=\"#Tensorflow-实现自编码器\" data-toc-modified-id=\"Tensorflow-实现自编码器-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Tensorflow 实现自编码器</a></div><div class=\"lev3 toc-item\"><a href=\"#导入库、模块和数据集\" data-toc-modified-id=\"导入库、模块和数据集-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>导入库、模块和数据集</a></div><div class=\"lev3 toc-item\"><a href=\"#初始化参数\" data-toc-modified-id=\"初始化参数-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>初始化参数</a></div><div class=\"lev3 toc-item\"><a href=\"#定义去噪自编码-class\" data-toc-modified-id=\"定义去噪自编码-class-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>定义去噪自编码 class</a></div><div class=\"lev4 toc-item\"><a href=\"#构建函数-__init__\" data-toc-modified-id=\"构建函数-__init__-1231\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>构建函数 <code>__init__</code></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自编码器和多层感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自编码器  \n",
    "\n",
    "- 深度学习可以解决难以提取有效特征的问题，缓解机器学习对特征工程的依赖\n",
    "  - 无监督学习：对数据内容的组织形式的学习，提取的是频繁出现的特征\n",
    "  - 逐层抽象：特征不断抽象，类似人从简单基础概念开始学习，再到复杂概念。从简单的微观特征开始，不断抽象特征层级，逐渐往复杂的宏观特征转变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征的稀疏表达\n",
    "\n",
    "- 使用少量的基本特征组合拼装得到更高层抽象的特征\n",
    "  - 几乎所有的图像碎片可以由 64 种正交的边组合而成\n",
    "  - 绝大多数声音可以由 20 种基本结构线性组合得到\n",
    "- 多层神经网络，每一层的前一层都是未加工的像素，而这一层是对像素进行加工组织成更高阶的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自编码器\n",
    "\n",
    "- 特征可以不断抽象转为高一级的特征，那如何找到这些基本结构，然后如何抽象？\n",
    "  - 有标注数据可以训练一个深层 NN\n",
    "  - 没有标注使用无监督的自编码器来提取特征\n",
    "- 自编码器就是可以使用自身的高阶特征编码自己\n",
    "  - 输入和输出一致\n",
    "  - 借助稀疏编码的思想，目标是使用稀疏的一些高阶特征重新组合来重构自己\n",
    "  - 特点：期望输入/输出一致；希望使用高阶特征来重构自己，而不只是复制像素点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于深度信念网络（DBN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用无监督的逐层训练提取特征，将网络的权重初始化到一个比较好的位置，辅助后面的监督训练\n",
    "- 无监督的逐层训练思想和自编码器非常相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自编码器的限制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自编码器通常希望使用少量稀疏的高阶特征来重构输入，所以可以加入几种限制：  \n",
    "\n",
    "#### L1 正则\n",
    "\n",
    "- 如果限制中间隐含层节点的数量，比如让隐层节点数量小于输入/输出节点数量，就相当于降维\n",
    "  - 和矩阵结合起来，矩阵的变换就是空间的变换，维度的变换\n",
    "- 学习重要的特征复原，去除不太相关的内容\n",
    "- 给中间层的权重加一个 L1 的正则，可以根据惩罚系数控制隐含节点的稀疏程度\n",
    "  - 惩罚系数越大，学到的特征组合越稀疏，实际使用（非零权重）的特征数量越少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加噪声\n",
    "\n",
    "- 加入噪声就是 Denoising AutoEncoder（去噪自编码器）\n",
    "- 从噪声中学习出数据特征\n",
    "  - 只有学习数据频繁出现的模式和结构，将无规律的噪声略去，才可以复原数据\n",
    "  - 高斯噪声（Additive Gaussian Noise，AGN）\n",
    "  - 有随机遮挡的噪声（Masking Noise）：一部分像素被置为 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果自编码器只有一层，类似于 PCA\n",
    "- Hinton 提出的 DBN 模型有多个隐层，每个隐层都是限制性玻尔兹曼机 RBM（Restricted Boltzman Machine，一种具有特殊连接分布的神经网络）\n",
    "  - DBN 训练时，需要先对每两层间进行无监督的预训练（整个过程相当于一个多层的自编码器，可以将整个网络的权重初始化到一个理想分布）\n",
    "  - 通过反向传播算法调整模型权重（会使用经过标注的信息来做监督性分类训练）\n",
    "- DBN 给训练深层的神经网络提供了可能性，能解决网络过深带来的梯度弥散（Gradient Vanishment）问题\n",
    "\n",
    "\n",
    "Hinton 的思想就是先用自编码器的方法进行无监督预训练，提取特征并初始化权重，然后适用标注信息进行监督式训练。  \n",
    "当然自编码器还可以直接进行特征提取和分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 实现自编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 去噪自编码器具有代表性，使用范围广，最通用\n",
    "- 无噪声自编码器只需要去掉噪声，并保证隐层节点小于输入层节点\n",
    "- Masking Noise 的自编码器只需要将高斯噪声改为随机遮挡噪声\n",
    "- Variational AutoEncoder（VAE）对中间节点的分布有强假设，拥有额外的损失项\n",
    "  - 使用特殊的 SGVB（Stochastic Gradient Variabional Bayes）算法进行训练\n",
    "  - 在生成模型中发挥很大作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入库、模块和数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 数据预处理常用模块\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参数初始化方法：xavier initialization\n",
    "  - 特点是会根据某一层网络的输入、输出节点数量自动调整最合适的分布\n",
    "  - 让权重满足 0 均值，同时方差为 $ \\dfrac {2}{n_{in} + n_{out}} $\n",
    "  - 分布可以用均匀分布或高斯分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过 `tf.random_uniform` 创建一个 $(- \\sqrt{\\frac {6} {n_{in} + n_{out}} }, \\sqrt{\\frac {6} {n_{in} + n_{out}} })$ 范围内的均匀分布\n",
    "- 方差根据 $ D(x) = (max - min)^2/12 = \\frac {2} {n_{in} + n_{out}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fan_in 节点输入数量，fan_out 节点输出数量\n",
    "\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval = low, maxval = high,\n",
    "                             dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义去噪自编码 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建函数 `__init__`  \n",
    "\n",
    "- `n_input`：输入变量数\n",
    "- `n_hidden`: 隐层节点数\n",
    "- `transfer_function`：隐层激活函数，默认为 softplus\n",
    "- `optimizer`：优化器，默认为 Adam\n",
    "- `scale`：高斯噪声系数，默认为 0.1\n",
    "- class 内的 `scale` 做成 placeholder\n",
    "- `_initialize_weights`：参数初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个隐含层\n",
    "\n",
    "class AdditiveGaussianNoiseAutoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function=tf.nn.softplus,\n",
    "                 optimizer=tf.train.AdamOptimizer(), scale=0.1):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
